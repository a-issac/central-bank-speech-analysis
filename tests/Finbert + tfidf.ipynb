{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze > aaa.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "import spacy\n",
    "\n",
    "#from tqdm.auto import tqdm \n",
    "#tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.language import Language\n",
    "from spacy_langdetect import LanguageDetector\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "\n",
    "@Language.factory(\"language_detector\")\n",
    "def create_language_detector(nlp, name):\n",
    "    return LanguageDetector(language_detection_function=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.2.0/en_core_web_sm-3.2.0.tar.gz\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.2.0/en_core_web_sm-3.2.0.tar.gz (13.9 MB)\n",
      "     |████████████████████████████████| 13.9 MB 3.6 MB/s            \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.3.0,>=3.2.0 in /opt/conda/lib/python3.9/site-packages (from en-core-web-sm==3.2.0) (3.2.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.7.5)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.20.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.6)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.8.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.3.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (58.2.0)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.6.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.6)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.4.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.62.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (21.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.9.0)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.2)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.4.0)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.0.13)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /opt/conda/lib/python3.9/site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.10.0.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.1)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.9/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from jinja2->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.1)\n",
      "Building wheels for collected packages: en-core-web-sm\n",
      "  Building wheel for en-core-web-sm (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for en-core-web-sm: filename=en_core_web_sm-3.2.0-py3-none-any.whl size=13900222 sha256=e847b0db78f220f3bb8c861b139dbc6949d58a6273534076836c02226359c1fd\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/6b/f3/e3/63027c0c01b21850a0b2ca7708201d27b9bbfbbeeeaa0b9b92\n",
      "Successfully built en-core-web-sm\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.2.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<spacytextblob.spacytextblob.SpacyTextBlob at 0x7f7af5a91640>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.2.0/en_core_web_sm-3.2.0.tar.gz\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "nlp.add_pipe('sentencizer')\n",
    "nlp.add_pipe('language_detector')\n",
    "nlp.add_pipe('spacytextblob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"https://www.ecb.europa.eu/press/key/shared/data/all_ECB_speeches.csv?848ea64ce6d77827b5e8e18790878b64\",index_col = [\"date\"] , sep = \"|\",encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speakers</th>\n",
       "      <th>title</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>contents</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-12-11</th>\n",
       "      <td>Gertrude Tumpel-Gugerell</td>\n",
       "      <td>The Way Forward with  Monetary, Fiscal and Mac...</td>\n",
       "      <td>Speech by Gertrude Tumpel-Gugerell, Member of ...</td>\n",
       "      <td>The Way Forward with Monetar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-05-08</th>\n",
       "      <td>Eugenio Domingo Solans</td>\n",
       "      <td>Catalunya dins l'Europa moderna</td>\n",
       "      <td>Eugenio Domingo Solans, Membre del Consell de ...</td>\n",
       "      <td>Catalunya dins l'Europa moderna  Eugenio Do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-06</th>\n",
       "      <td>Yves Mersch</td>\n",
       "      <td>Challenges for euro area monetary policy in e...</td>\n",
       "      <td>Speech by Yves Mersch, Member of the Executive...</td>\n",
       "      <td>Challenges for euro area monetary policy in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-17</th>\n",
       "      <td>Luis de Guindos</td>\n",
       "      <td>Speaking notes on climate-related risks</td>\n",
       "      <td>Speaking notes by Luis de Guindos, Vice-Presid...</td>\n",
       "      <td>SPEAKING NOTES Washington, D.C., 17 October...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-14</th>\n",
       "      <td>Fabio Panetta</td>\n",
       "      <td>A commitment to the recovery</td>\n",
       "      <td>Speech by Fabio Panetta, Member of the Executi...</td>\n",
       "      <td>SPEECH  A commitment to the recovery    Spe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-05-17</th>\n",
       "      <td>Yves Mersch</td>\n",
       "      <td>“Built to Last”: The New Euro Area Framework</td>\n",
       "      <td>Speech by Yves Mersch, Member of the Executive...</td>\n",
       "      <td>“Built to Last”: The New Euro Area Framework...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-13</th>\n",
       "      <td>Yves Mersch</td>\n",
       "      <td>“Europe after the warm reboot”</td>\n",
       "      <td>Speech by Yves Mersch, Member of the Executive...</td>\n",
       "      <td>“Europe after the warm reboot”    Speech by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-16</th>\n",
       "      <td>Vítor Constâncio</td>\n",
       "      <td>“Monetary policy and the euro area problem”</td>\n",
       "      <td>Speech by Vítor Constâncio, Vice-President of ...</td>\n",
       "      <td>“Monetary policy and the euro area problem” ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-03-15</th>\n",
       "      <td>José Manuel González-Páramo</td>\n",
       "      <td>“What has Europe learnt from the crisis”?</td>\n",
       "      <td>Speech by José Manuel González-Páramo, Member ...</td>\n",
       "      <td>“What has Europe learnt from the crisis”?   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-06</th>\n",
       "      <td>Jean-Claude Trichet</td>\n",
       "      <td>“What role for finance?”</td>\n",
       "      <td>University lecture by Jean-Claude Trichet, Pre...</td>\n",
       "      <td>“What role for finance?”   University lectur...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2513 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               speakers  \\\n",
       "date                                      \n",
       "2009-12-11     Gertrude Tumpel-Gugerell   \n",
       "2003-05-08       Eugenio Domingo Solans   \n",
       "2017-12-06                  Yves Mersch   \n",
       "2019-10-17              Luis de Guindos   \n",
       "2020-12-14                Fabio Panetta   \n",
       "...                                 ...   \n",
       "2013-05-17                  Yves Mersch   \n",
       "2014-01-13                  Yves Mersch   \n",
       "2015-11-16             Vítor Constâncio   \n",
       "2012-03-15  José Manuel González-Páramo   \n",
       "2010-05-06          Jean-Claude Trichet   \n",
       "\n",
       "                                                        title  \\\n",
       "date                                                            \n",
       "2009-12-11  The Way Forward with  Monetary, Fiscal and Mac...   \n",
       "2003-05-08                    Catalunya dins l'Europa moderna   \n",
       "2017-12-06   Challenges for euro area monetary policy in e...   \n",
       "2019-10-17            Speaking notes on climate-related risks   \n",
       "2020-12-14                      A commitment to the recovery    \n",
       "...                                                       ...   \n",
       "2013-05-17       “Built to Last”: The New Euro Area Framework   \n",
       "2014-01-13                     “Europe after the warm reboot”   \n",
       "2015-11-16        “Monetary policy and the euro area problem”   \n",
       "2012-03-15          “What has Europe learnt from the crisis”?   \n",
       "2010-05-06                           “What role for finance?”   \n",
       "\n",
       "                                                     subtitle  \\\n",
       "date                                                            \n",
       "2009-12-11  Speech by Gertrude Tumpel-Gugerell, Member of ...   \n",
       "2003-05-08  Eugenio Domingo Solans, Membre del Consell de ...   \n",
       "2017-12-06  Speech by Yves Mersch, Member of the Executive...   \n",
       "2019-10-17  Speaking notes by Luis de Guindos, Vice-Presid...   \n",
       "2020-12-14  Speech by Fabio Panetta, Member of the Executi...   \n",
       "...                                                       ...   \n",
       "2013-05-17  Speech by Yves Mersch, Member of the Executive...   \n",
       "2014-01-13  Speech by Yves Mersch, Member of the Executive...   \n",
       "2015-11-16  Speech by Vítor Constâncio, Vice-President of ...   \n",
       "2012-03-15  Speech by José Manuel González-Páramo, Member ...   \n",
       "2010-05-06  University lecture by Jean-Claude Trichet, Pre...   \n",
       "\n",
       "                                                     contents  \n",
       "date                                                           \n",
       "2009-12-11                    The Way Forward with Monetar...  \n",
       "2003-05-08     Catalunya dins l'Europa moderna  Eugenio Do...  \n",
       "2017-12-06     Challenges for euro area monetary policy in...  \n",
       "2019-10-17     SPEAKING NOTES Washington, D.C., 17 October...  \n",
       "2020-12-14     SPEECH  A commitment to the recovery    Spe...  \n",
       "...                                                       ...  \n",
       "2013-05-17    “Built to Last”: The New Euro Area Framework...  \n",
       "2014-01-13    “Europe after the warm reboot”    Speech by ...  \n",
       "2015-11-16    “Monetary policy and the euro area problem” ...  \n",
       "2012-03-15    “What has Europe learnt from the crisis”?   ...  \n",
       "2010-05-06    “What role for finance?”   University lectur...  \n",
       "\n",
       "[2513 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df = df[df[\"contents\"]!=\" \"]\n",
    "df.sort_values(\"contents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### /!\\ Prend beaucoup de temps\n",
    "\n",
    "df[\"nlp\"] = df[\"contents\"].apply(lambda x: nlp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df[df['nlp'].apply(lambda x: x._.language['language']==\"en\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sentences\"] = df[\"nlp\"].apply(lambda y : [str(x) for x in list(y.sents)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.drop(columns=['contents', 'nlp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import numpy as np\n",
    "finbert = BertForSequenceClassification.from_pretrained('yiyanghkust/finbert-tone',num_labels=3)\n",
    "tokenizer = BertTokenizer.from_pretrained('yiyanghkust/finbert-tone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finbert_result(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True)\n",
    "    outputs = finbert(**inputs)[0]\n",
    "    score = {0:0, 1:1, 2:-1}\n",
    "    return np.vectorize(lambda x: score[x])(np.argmax(outputs.detach().numpy(), axis = 1)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finbert_result(df[\"finbertscore\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-00cf07b74dcd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I represent the BCE ---- [ 5.89971   -6.314463  -3.9419703]\n",
      "the sky is grey ---- [ 6.2517743 -7.200073  -2.525556 ]\n",
      "the sky is blue ---- [ 6.007808  -4.8922215 -3.1983948]\n",
      "I am happy ---- [-3.57437    7.118817  -5.7525463]\n"
     ]
    }
   ],
   "source": [
    "sentences = [\"I represent the BCE\", \n",
    "             \"the sky is grey\", \n",
    "             \"the sky is blue\", \n",
    "             \"I am happy\"]\n",
    "\n",
    "inputs = tokenizer(sentences, return_tensors=\"pt\", padding=True)\n",
    "outputs = finbert(**inputs)[0]\n",
    "\n",
    "labels = {0:'neutral', 1:'positive',2:'negative'}\n",
    "for idx, sent in enumerate(sentences):\n",
    "    print(sent, '----', outputs.detach().numpy()[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = {0:0, 1:1, 2:-1}\n",
    "np.vectorize(lambda x: score[x])(np.argmax(outputs.detach().numpy(), axis = 1)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[nlp(x)._.polarity for x in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.8997, -6.3145, -3.9420],\n",
       "        [ 6.2518, -7.2001, -2.5256],\n",
       "        [ 6.0078, -4.8922, -3.1984],\n",
       "        [-3.5744,  7.1188, -5.7525]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "v = TfidfVectorizer(stop_words=\"english\")\n",
    "tfidf_vector = v.fit_transform(df[\"nlp\"].apply(lambda x: x.text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df = pd.DataFrame(tfidf_vector.toarray(), index=df.index, columns=v.get_feature_names())\n",
    "tfidf_df = tfidf_df.stack().reset_index()\n",
    "tfidf_df = tfidf_df.rename(columns={0:'tfidf', 'level_0': 'document','level_1': 'term', 'level_2': 'term'})\n",
    "tfidf_df.sort_values(by=['date','tfidf'], ascending=[True,False]).groupby(['date']).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatizer.lemmatize(\"happiness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_docs(texts, remove_stopwords=True, n_process = 4):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    docs = nlp.pipe(texts, \n",
    "                    disable=['parser','lemmatizer' ,'ner','textcat'])\n",
    "    stopwords = nlp.Defaults.stop_words\n",
    "\n",
    "    docs_cleaned = []\n",
    "    for doc in docs:\n",
    "        tokens = [tok.text.lower().strip() for tok in doc if not tok.is_punct]\n",
    "        if remove_stopwords:\n",
    "            tokens = [ps.stem(tok) for tok in tokens if tok not in stopwords]\n",
    "        doc_clean = ' '.join(tokens)\n",
    "        docs_cleaned.append(doc_clean)\n",
    "        \n",
    "    return docs_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa = df[\"contents\"].sample(1)\n",
    "cleaned = clean_docs(aaa, remove_stopwords=True)\n",
    "cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "v = TfidfVectorizer()\n",
    "tfidf_vector = v.fit_transform(clean_docs(df[\"contents\"]))\n",
    "tfidf_df = pd.DataFrame(tfidf_vector.toarray(), index=df.index, columns=v.get_feature_names())\n",
    "tfidf_df = tfidf_df.stack().reset_index()\n",
    "tfidf_df = tfidf_df.rename(columns={0:'tfidf', 'level_0': 'document','level_1': 'term', 'level_2': 'term'})\n",
    "tfidf_df.sort_values(by=['date','tfidf'], ascending=[True,False]).groupby(['date']).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vector = v.fit_transform(clean_docs(df[\"contents\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df = pd.DataFrame(tfidf_vector.toarray(), index=df.index, columns=v.get_feature_names())\n",
    "tfidf_df = tfidf_df.stack().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df = tfidf_df.rename(columns={0:'tfidf', 'level_0': 'document','level_1': 'term', 'level_2': 'term'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "  \n",
    "ps = PorterStemmer()\n",
    " \n",
    "# choose some words to be stemmed\n",
    "words = [\"I\", \"am\",\"happy\",\"but\",\"he\",\"is\",\"not\"]\n",
    "for word in words:\n",
    "    print(ps.stem(lemmatizer.lemmatize(word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df = tfidf_df.sort_values(by=['date','tfidf'], ascending=[True,False]).groupby(['date']).head(10)\n",
    "tfidf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
