{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "import spacy\n",
    "\n",
    "#from tqdm.auto import tqdm \n",
    "#tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.language import Language\n",
    "from spacy_langdetect import LanguageDetector\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "\n",
    "@Language.factory(\"language_detector\")\n",
    "def create_language_detector(nlp, name):\n",
    "    return LanguageDetector(language_detection_function=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacytextblob.spacytextblob.SpacyTextBlob at 0x29bae8afe80>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "nlp.add_pipe('sentencizer')\n",
    "nlp.add_pipe('language_detector')\n",
    "nlp.add_pipe('spacytextblob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"https://www.ecb.europa.eu/press/key/shared/data/all_ECB_speeches.csv?848ea64ce6d77827b5e8e18790878b64\",index_col = [\"date\"] , sep = \"|\",encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speakers</th>\n",
       "      <th>title</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>contents</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-12-11</th>\n",
       "      <td>Gertrude Tumpel-Gugerell</td>\n",
       "      <td>The Way Forward with  Monetary, Fiscal and Mac...</td>\n",
       "      <td>Speech by Gertrude Tumpel-Gugerell, Member of ...</td>\n",
       "      <td>The Way Forward with Monetar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-05-08</th>\n",
       "      <td>Eugenio Domingo Solans</td>\n",
       "      <td>Catalunya dins l'Europa moderna</td>\n",
       "      <td>Eugenio Domingo Solans, Membre del Consell de ...</td>\n",
       "      <td>Catalunya dins l'Europa moderna  Eugenio Do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-06</th>\n",
       "      <td>Yves Mersch</td>\n",
       "      <td>Challenges for euro area monetary policy in e...</td>\n",
       "      <td>Speech by Yves Mersch, Member of the Executive...</td>\n",
       "      <td>Challenges for euro area monetary policy in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-17</th>\n",
       "      <td>Luis de Guindos</td>\n",
       "      <td>Speaking notes on climate-related risks</td>\n",
       "      <td>Speaking notes by Luis de Guindos, Vice-Presid...</td>\n",
       "      <td>SPEAKING NOTES Washington, D.C., 17 October...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-14</th>\n",
       "      <td>Fabio Panetta</td>\n",
       "      <td>A commitment to the recovery</td>\n",
       "      <td>Speech by Fabio Panetta, Member of the Executi...</td>\n",
       "      <td>SPEECH  A commitment to the recovery    Spe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-05-17</th>\n",
       "      <td>Yves Mersch</td>\n",
       "      <td>“Built to Last”: The New Euro Area Framework</td>\n",
       "      <td>Speech by Yves Mersch, Member of the Executive...</td>\n",
       "      <td>“Built to Last”: The New Euro Area Framework...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-13</th>\n",
       "      <td>Yves Mersch</td>\n",
       "      <td>“Europe after the warm reboot”</td>\n",
       "      <td>Speech by Yves Mersch, Member of the Executive...</td>\n",
       "      <td>“Europe after the warm reboot”    Speech by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-16</th>\n",
       "      <td>Vítor Constâncio</td>\n",
       "      <td>“Monetary policy and the euro area problem”</td>\n",
       "      <td>Speech by Vítor Constâncio, Vice-President of ...</td>\n",
       "      <td>“Monetary policy and the euro area problem” ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-03-15</th>\n",
       "      <td>José Manuel González-Páramo</td>\n",
       "      <td>“What has Europe learnt from the crisis”?</td>\n",
       "      <td>Speech by José Manuel González-Páramo, Member ...</td>\n",
       "      <td>“What has Europe learnt from the crisis”?   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-06</th>\n",
       "      <td>Jean-Claude Trichet</td>\n",
       "      <td>“What role for finance?”</td>\n",
       "      <td>University lecture by Jean-Claude Trichet, Pre...</td>\n",
       "      <td>“What role for finance?”   University lectur...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2513 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               speakers  \\\n",
       "date                                      \n",
       "2009-12-11     Gertrude Tumpel-Gugerell   \n",
       "2003-05-08       Eugenio Domingo Solans   \n",
       "2017-12-06                  Yves Mersch   \n",
       "2019-10-17              Luis de Guindos   \n",
       "2020-12-14                Fabio Panetta   \n",
       "...                                 ...   \n",
       "2013-05-17                  Yves Mersch   \n",
       "2014-01-13                  Yves Mersch   \n",
       "2015-11-16             Vítor Constâncio   \n",
       "2012-03-15  José Manuel González-Páramo   \n",
       "2010-05-06          Jean-Claude Trichet   \n",
       "\n",
       "                                                        title  \\\n",
       "date                                                            \n",
       "2009-12-11  The Way Forward with  Monetary, Fiscal and Mac...   \n",
       "2003-05-08                    Catalunya dins l'Europa moderna   \n",
       "2017-12-06   Challenges for euro area monetary policy in e...   \n",
       "2019-10-17            Speaking notes on climate-related risks   \n",
       "2020-12-14                      A commitment to the recovery    \n",
       "...                                                       ...   \n",
       "2013-05-17       “Built to Last”: The New Euro Area Framework   \n",
       "2014-01-13                     “Europe after the warm reboot”   \n",
       "2015-11-16        “Monetary policy and the euro area problem”   \n",
       "2012-03-15          “What has Europe learnt from the crisis”?   \n",
       "2010-05-06                           “What role for finance?”   \n",
       "\n",
       "                                                     subtitle  \\\n",
       "date                                                            \n",
       "2009-12-11  Speech by Gertrude Tumpel-Gugerell, Member of ...   \n",
       "2003-05-08  Eugenio Domingo Solans, Membre del Consell de ...   \n",
       "2017-12-06  Speech by Yves Mersch, Member of the Executive...   \n",
       "2019-10-17  Speaking notes by Luis de Guindos, Vice-Presid...   \n",
       "2020-12-14  Speech by Fabio Panetta, Member of the Executi...   \n",
       "...                                                       ...   \n",
       "2013-05-17  Speech by Yves Mersch, Member of the Executive...   \n",
       "2014-01-13  Speech by Yves Mersch, Member of the Executive...   \n",
       "2015-11-16  Speech by Vítor Constâncio, Vice-President of ...   \n",
       "2012-03-15  Speech by José Manuel González-Páramo, Member ...   \n",
       "2010-05-06  University lecture by Jean-Claude Trichet, Pre...   \n",
       "\n",
       "                                                     contents  \n",
       "date                                                           \n",
       "2009-12-11                    The Way Forward with Monetar...  \n",
       "2003-05-08     Catalunya dins l'Europa moderna  Eugenio Do...  \n",
       "2017-12-06     Challenges for euro area monetary policy in...  \n",
       "2019-10-17     SPEAKING NOTES Washington, D.C., 17 October...  \n",
       "2020-12-14     SPEECH  A commitment to the recovery    Spe...  \n",
       "...                                                       ...  \n",
       "2013-05-17    “Built to Last”: The New Euro Area Framework...  \n",
       "2014-01-13    “Europe after the warm reboot”    Speech by ...  \n",
       "2015-11-16    “Monetary policy and the euro area problem” ...  \n",
       "2012-03-15    “What has Europe learnt from the crisis”?   ...  \n",
       "2010-05-06    “What role for finance?”   University lectur...  \n",
       "\n",
       "[2513 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df = df[df[\"contents\"]!=\" \"]\n",
    "df.sort_values(\"contents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"nlp\"] = df[\"contents\"].apply(lambda x: nlp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df[df['nlp'].apply(lambda x: x._.language['language']==\"en\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sentences\"] = df[\"nlp\"].apply(lambda y : [str(x) for x in list(y.sents)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BertForSequenceClassification' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-6bed641fb144>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfinbert\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBertForSequenceClassification\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'yiyanghkust/finbert-tone'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_labels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'yiyanghkust/finbert-tone'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfinbert_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"pt\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'BertForSequenceClassification' is not defined"
     ]
    }
   ],
   "source": [
    "finbert = BertForSequenceClassification.from_pretrained('yiyanghkust/finbert-tone',num_labels=3)\n",
    "tokenizer = BertTokenizer.from_pretrained('yiyanghkust/finbert-tone')\n",
    "\n",
    "def finbert_result(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True)\n",
    "    outputs = finbert(**inputs)[0]\n",
    "    score = {0:0, 1:1, 2:-1}\n",
    "    return np.vectorize(lambda x: score[x])(np.argmax(outputs.detach().numpy(), axis = 1)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'finbert_result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-1391709f4da9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfinbert_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"finbertscore\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'finbert_result' is not defined"
     ]
    }
   ],
   "source": [
    "finbert_result(df[\"finbertscore\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['contents', 'nlp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I represent the BCE ---- [ 5.89971   -6.314463  -3.9419703]\n",
      "the sky is grey ---- [ 6.2517743 -7.200073  -2.525556 ]\n",
      "the sky is blue ---- [ 6.007808  -4.8922215 -3.1983948]\n",
      "I am happy ---- [-3.57437    7.118817  -5.7525463]\n"
     ]
    }
   ],
   "source": [
    "sentences = [\"I represent the BCE\", \n",
    "             \"the sky is grey\", \n",
    "             \"the sky is blue\", \n",
    "             \"I am happy\"]\n",
    "\n",
    "inputs = tokenizer(sentences, return_tensors=\"pt\", padding=True)\n",
    "outputs = finbert(**inputs)[0]\n",
    "\n",
    "labels = {0:'neutral', 1:'positive',2:'negative'}\n",
    "for idx, sent in enumerate(sentences):\n",
    "    print(sent, '----', outputs.detach().numpy()[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = {0:0, 1:1, 2:-1}\n",
    "np.vectorize(lambda x: score[x])(np.argmax(outputs.detach().numpy(), axis = 1)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[nlp(x)._.polarity for x in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.8997, -6.3145, -3.9420],\n",
       "        [ 6.2518, -7.2001, -2.5256],\n",
       "        [ 6.0078, -4.8922, -3.1984],\n",
       "        [-3.5744,  7.1188, -5.7525]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "v = TfidfVectorizer(stop_words=\"english\")\n",
    "tfidf_vector = v.fit_transform(df[\"nlp\"].apply(lambda x: x.text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df = pd.DataFrame(tfidf_vector.toarray(), index=df.index, columns=v.get_feature_names())\n",
    "tfidf_df = tfidf_df.stack().reset_index()\n",
    "tfidf_df = tfidf_df.rename(columns={0:'tfidf', 'level_0': 'document','level_1': 'term', 'level_2': 'term'})\n",
    "tfidf_df.sort_values(by=['date','tfidf'], ascending=[True,False]).groupby(['date']).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatizer.lemmatize(\"happiness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_docs(texts, remove_stopwords=True, n_process = 4):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    docs = nlp.pipe(texts, \n",
    "                    disable=['parser','lemmatizer' ,'ner','textcat'])\n",
    "    stopwords = nlp.Defaults.stop_words\n",
    "\n",
    "    docs_cleaned = []\n",
    "    for doc in docs:\n",
    "        tokens = [tok.text.lower().strip() for tok in doc if not tok.is_punct]\n",
    "        if remove_stopwords:\n",
    "            tokens = [ps.stem(tok) for tok in tokens if tok not in stopwords]\n",
    "        doc_clean = ' '.join(tokens)\n",
    "        docs_cleaned.append(doc_clean)\n",
    "        \n",
    "    return docs_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa = df[\"contents\"].sample(1)\n",
    "cleaned = clean_docs(aaa, remove_stopwords=True)\n",
    "cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "v = TfidfVectorizer()\n",
    "tfidf_vector = v.fit_transform(clean_docs(df[\"contents\"]))\n",
    "tfidf_df = pd.DataFrame(tfidf_vector.toarray(), index=df.index, columns=v.get_feature_names())\n",
    "tfidf_df = tfidf_df.stack().reset_index()\n",
    "tfidf_df = tfidf_df.rename(columns={0:'tfidf', 'level_0': 'document','level_1': 'term', 'level_2': 'term'})\n",
    "tfidf_df.sort_values(by=['date','tfidf'], ascending=[True,False]).groupby(['date']).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vector = v.fit_transform(clean_docs(df[\"contents\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df = pd.DataFrame(tfidf_vector.toarray(), index=df.index, columns=v.get_feature_names())\n",
    "tfidf_df = tfidf_df.stack().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df = tfidf_df.rename(columns={0:'tfidf', 'level_0': 'document','level_1': 'term', 'level_2': 'term'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "  \n",
    "ps = PorterStemmer()\n",
    " \n",
    "# choose some words to be stemmed\n",
    "words = [\"I\", \"am\",\"happy\",\"but\",\"he\",\"is\",\"not\"]\n",
    "for word in words:\n",
    "    print(ps.stem(lemmatizer.lemmatize(word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df = tfidf_df.sort_values(by=['date','tfidf'], ascending=[True,False]).groupby(['date']).head(10)\n",
    "tfidf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps.stem(\"Hungarian\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
